{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ac38f12a7050c0e4c45e970deee18ddce29c153571c006b6348cb061b04b8622"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6 pages created:\n['index.html', 'grapes.html', 'wine_grapes.html', 'table_grapes.html', 'dried_grapes.html', 'vineyards.html']\n"
     ]
    }
   ],
   "source": [
    "data_filepath = 'the average human being - old data.csv'\n",
    "\n",
    "import markdown\n",
    "def fact_page_html(url='', fact='', source='', note='', url_list=[], start_page=False, **kwargs):\n",
    "    # check that inputs are correct types\n",
    "    if not isinstance(url, str):\n",
    "        raise TypeError('url needs to be a string')\n",
    "    if not isinstance(fact, str):\n",
    "        raise TypeError('fact needs to be a string')\n",
    "    if not isinstance(source, str):\n",
    "        raise TypeError('source needs to be a string')\n",
    "    if not isinstance(note, str):\n",
    "        raise TypeError('note needs to be a string')\n",
    "    if not isinstance(url_list, list):\n",
    "        raise TypeError('url_list needs to be a list of strings')\n",
    "    if not isinstance(start_page, bool):\n",
    "        raise TypeError('start_page needs to be True or False')\n",
    "\n",
    "    # check that required arguments are present\n",
    "    if not url:\n",
    "        raise ValueError('url is required')\n",
    "    if not url_list:\n",
    "        raise ValueError('url_list is required')\n",
    "\n",
    "    # compute intermediate html chunks\n",
    "    if source:\n",
    "        source_html = f'<div><h2>Source:</h2> {markdown.markdown(source)}</div>'\n",
    "    else:\n",
    "        source_html = ''\n",
    "\n",
    "    if note:\n",
    "        note_html = f'<div><h2>Note:</h2> {markdown.markdown(note)}</div>'\n",
    "    else:\n",
    "        note_html = ''\n",
    "\n",
    "    title = f'The average human being {fact}'\n",
    "\n",
    "    if start_page:\n",
    "        start_page_script = f\"\"\"\\\n",
    "            <script>\n",
    "                var urls = {url_list};\n",
    "                location.href = urls[Math.floor(Math.random() * urls.length)];\n",
    "            </script>\n",
    "            \"\"\"\n",
    "        import textwrap\n",
    "        start_page_script = textwrap.dedent(start_page_script)\n",
    "    else:\n",
    "        start_page_script = ''\n",
    "\n",
    "\n",
    "    # load template\n",
    "    with open('fact_page_template.html', 'r') as fact_page_template_file:\n",
    "        fact_page_template_string = fact_page_template_file.read()\n",
    "\n",
    "    # return completed template\n",
    "    return fact_page_template_string.format(\n",
    "        url=url, \n",
    "        fact=fact, \n",
    "        title=title, \n",
    "        source_html=source_html, \n",
    "        note_html=note_html, \n",
    "        url_list=url_list,\n",
    "        start_page_script=start_page_script\n",
    "        )\n",
    "\n",
    "\n",
    "import csv\n",
    "with open(data_filepath, 'r') as data_file:\n",
    "    # read csv, load all rows\n",
    "    reader = csv.DictReader(data_file, delimiter=',')\n",
    "    fact_dicts = [fact_dict for fact_dict in reader]\n",
    "\n",
    "    # create url list and insert into fact dicts\n",
    "    url_list = [fact_dict['url'] for fact_dict in fact_dicts]\n",
    "    for fact_dict in fact_dicts:\n",
    "        url_list_without_self = [url for url in url_list if url != fact_dict['url']]\n",
    "        fact_dict['url_list'] = url_list_without_self\n",
    "\n",
    "    # create start page\n",
    "    with open('index.html', 'w') as start_page:\n",
    "        start_page.write(fact_page_html(url='index.html', url_list=url_list, start_page=True))\n",
    "\n",
    "    # convert urls - PUT AFTER PAGE CREATION IF YOU WANT LINKS WITHOUT HTML SUFFIX\n",
    "    for fact_dict in fact_dicts:\n",
    "        fact_dict['url'] = fact_dict['url'] + '.html'\n",
    "\n",
    "    # create pages\n",
    "    for fact_dict in fact_dicts:\n",
    "        with open(fact_dict['url'], 'w') as fact_page:\n",
    "            fact_page.write(fact_page_html(**fact_dict))\n",
    "print(f'{1+len(fact_dicts)} pages created:')\n",
    "print(['index.html'] + url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}